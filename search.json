[
  {
    "objectID": "EspressoLocomotion.html",
    "href": "EspressoLocomotion.html",
    "title": "loco_nbdev",
    "section": "",
    "text": "class EspressoLocomotion(object):\n    def __init__(self, dataFolder, startMin, endMin, companionEspObj=None, initialResamplePeriod=50, smoothing=True, longForm=False):\n        self.version = '0.1.5'\n        if dataFolder[-1] != '/':\n            dataFolder = dataFolder+'/'\n        self.metaDataDf, self.countLogDf, self.portLocationsDf, self.experimentSummary = locoDataMunger.readMetaAndCount(\n            dataFolder, companionEspObj, startMin, endMin, initialResamplePeriod, smoothing, longForm)\n        outputDir = locoUtilities.makeOutputFolders(dataFolder)\n        self.dataFolder = dataFolder\n        self.outputFolder = outputDir\n        self.startMin = startMin\n        self.endMin = endMin\n        self.resultsDf = self.metaDataDf\n        self.resultsDf['averageSpeed_mm/s'] = np.nanmean(\n            self.countLogDf.filter(regex='_V'), axis=0)\n        self.resultsDf['xPosition_mm'] = np.nanmean(\n            self.countLogDf.filter(regex='_X'), axis=0)\n        self.resultsDf['yPosition_mm'] = np.nanmean(\n            self.countLogDf.filter(regex='_Y'), axis=0)\n        self.resultsDf['inLeftPort'] = np.nanmean(\n            100*(self.countLogDf.filter(regex='LeftPort') > 0), axis=0)\n        self.resultsDf['inRightPort'] = np.nanmean(\n            100*(self.countLogDf.filter(regex='RightPort') > 0), axis=0)\n        if any(self.experimentSummary.countLogDate.str.contains(self.resultsDf.Date[0])):\n            self.resultsDf['countLogDate'] = self.resultsDf['Date']\n            self.resultsDf['feedLogDate'] = [self.experimentSummary.loc[self.experimentSummary['countLogDate']\n                                                                        == d]['feedLogDate'].iloc[0] for d in self.resultsDf['Date']]\n        else:\n            self.resultsDf['feedLogDate'] = self.resultsDf['Date']\n            self.resultsDf['countLogDate'] = [self.experimentSummary.loc[self.experimentSummary['feedLogDate']\n                                                                         == d]['countLogDate'].iloc[0] for d in self.resultsDf['Date']]\n\n\ndef versionNotes(self):\n        print('version notes 0.1.1: added portlocations')\n        print('version notes 0.1.2: added gaussian smoothing of x y locations')\n        print('version notes 0.1.3: added detection of fall events')\n        print('version notes 0.1.4: bugfix setfont and moved colorbar on heatmap to bottom')\n        print('version notes 0.1.5: added handling of dabest 0.3.9999')\n        print('version notes 0.2.0: major refactoring')\n\n\ndef plotChamberSmallMultiples(self, ncol=15, customPalette=None, setNumber=None):\n        dates = self.metaDataDf.Date.unique()\n        chamberSmallsTrack = np.empty(len(dates), dtype=object)\n        axarrT = np.empty(len(dates), dtype=object)\n        chamberSmallsHeat = np.empty(len(dates), dtype=object)\n        axarrH = np.empty(len(dates), dtype=object)\n        print('Espresso Runs found:\\n')\n        print(dates)\n        if setNumber is not None:\n            dates = [dates[setNumber]]\n        for i in range(0, len(dates)):\n            print('\\n\\n plotting ' + dates[i] + '...')\n            portFile = self.experimentSummary.loc[self.experimentSummary['metaDataFile']\n                                                  == 'MetaData_'+dates[i] + '.csv']['portLocationsFile'].iloc[0]\n            portDate = locoDataMunger.extractDateStr(portFile)[0]\n            submeta = self.metaDataDf.loc[self.metaDataDf.Date == dates[i]]\n            subcount = self.countLogDf.filter(regex=dates[i])\n            subport = self.portLocationsDf.loc[self.portLocationsDf.Date == portDate]\n            chamberSmallsTrack[i], axarrT[i] = locoPlotters.putThingsInToChamberSubplot(\n                subcount, submeta, subport, customPalette, ncol)\n            chamberSmallsHeat[i], axarrH[i] = locoPlotters.putThingsInToChamberSubplot(\n                subcount, submeta, subport, customPalette, ncol, locoPlotters.espressoPlotHeatmap)\n            outputDir = self.outputFolder + 'chamberPlots/'\n            locoUtilities.espressoSaveFig(\n                chamberSmallsTrack[i], 'chamberSmallsTrack', dates[i], outputDir, pngDPI=200)\n            locoUtilities.espressoSaveFig(\n                chamberSmallsHeat[i], 'chamberSmallsHeat', dates[i], outputDir, pngDPI=200)\n        self.chamberSmallsTrack = chamberSmallsTrack\n        self.axarrT = axarrT\n        self.chamberSmallsHeat = chamberSmallsHeat\n        self.axarrH = axarrH\n        return chamberSmallsTrack, axarrT, chamberSmallsHeat, axarrH\n\n\ndef plotMeanHeatMaps(self, binSize=0.2, row=None, col=None, reverseRows=False, reverseCols=False,  verbose=False, heatmapCMap='RdYlBu_r', smooth=2):\n        heatMapOutputDir = self.outputFolder\n        if verbose:\n            meanHeatmapFig,  Hall, images, smallHeatmapFigs = locoPlotters.espressoPlotMeanHeatmaps(\n                self, binSize, None, None, False, False, verbose, heatmapCMap, smooth)\n            locoUtilities.espressoSaveFig(\n                smallHeatmapFigs, 'smallHeatmapFigs', self.metaDataDf.Date[0], heatMapOutputDir, pngDPI=200)\n        else:\n            meanHeatmapFig, Hall, images = locoPlotters.espressoPlotMeanHeatmaps(\n                self, binSize, row, col, reverseRows, reverseCols, verbose, heatmapCMap, smooth)\n        # self.resultsDf = resultsDf\n        self.heatmapMatrix = Hall\n        self.meanHeatmapFig = meanHeatmapFig\n        self.heatmapImages = images\n\n\ndef plotBoundedLines(self,  colorBy, locoSuffix='V', row=None, col=None, rp='300s', YLim=[], customPalette={}, reverseRows=False, reverseCol=False, xUnit='min'):\n        if xUnit == 'hour':\n            T = self.countLogDf.iloc[:, 0]/3600\n        else:\n            T = self.countLogDf.iloc[:, 0]/60\n\n        if 'Port' in locoSuffix:\n            metric = 100*(self.countLogDf.filter(regex='_' + locoSuffix) > 0)\n        else:\n            metric = self.countLogDf.filter(regex='_' + locoSuffix)\n\n        listOfPlots, gp, cPalette = locoPlotters.subplotRowColColor(\n            self.metaDataDf, colorBy, row, col, reverseRows, reverseCol)\n        if customPalette:\n            cPalette = customPalette\n        nr, nc = listOfPlots[-1][0][0:2]\n        figure, axes = plt.subplots(\n            nrows=nr + 1, ncols=nc + 1, squeeze=False, figsize=(3 * (nc + 1), 3 * (nr + 1)))\n        plotNames = [0]*len(listOfPlots)\n        meanLines = [0]*len(listOfPlots)\n        ciBounds = [0]*len(listOfPlots)\n\n        yl = {'V': 'Average Speed (mm/s)', 'X': 'X Position (mm)', 'Y': 'Y Position (mm)',\n              'InLeftPort': 'Percent time in Left Port',  'InRightPort': 'Percent time in Right Port'}\n        for i in range(0, len(listOfPlots)):\n            # print(listOfPlots[i])\n            ro, co = listOfPlots[i][0][0:2]\n            name = listOfPlots[i][1]\n            ind = gp[name]\n            locoPlotters.plotBoundedLine(\n                T, metric.iloc[:, ind], ax=axes[ro, co], c=cPalette[name[-1]], resamplePeriod=rp)\n            meanLines[i] = axes[ro, co].meanLine[0]\n            ciBounds[i] = axes[ro, co].ciBound\n            if co == 0:\n                axes[ro, co].set_ylabel(yl[locoSuffix])\n            if ro == axes.shape[0]:\n                axes[ro, co].set_xlabel('Time (hour)')\n            axes[ro, co].set_title(name[0] + ' ' + name[1])\n            axes[ro, co]. spines[\"right\"].set_visible(False)\n            axes[ro, co]. spines[\"top\"].set_visible(False)\n            plotNames[i] = name[-1]\n        ylims = [ax.get_ylim() for ax in axes.flatten()]\n        for i in range(0, len(listOfPlots)):\n            ro, co = listOfPlots[i][0][0:2]\n            if len(YLim) > 0:\n                axes[ro, co].set_ylim(YLim)\n            else:\n                axes[ro, co].set_ylim([np.min(ylims), np.max(ylims)])\n            locoPlotters.setAxesTicks(axes[ro, co], True, gridState=False)\n\n        axes[ro, co].legend(plotNames, loc='upper right')\n\n        locoUtilities.espressoSaveFig(\n            figure, 'boundedTS_' + locoSuffix + '_', self.metaDataDf.Date[0], self.outputFolder)\n\n        return figure, axes, meanLines, ciBounds\n\n\ndef calculatePeriFeedSpeed(self, companionEspObj, monitorWindow=120, startSeconds=0):\n\n        self.feedsRevisedDf, self.countLogDf, self.meanPeriSpeed, self.maxSpeed= locoDataMunger.calculatePeriFeedLoco(\n            self.countLogDf, self.portLocationsDf, companionEspObj, self.experimentSummary, monitorWindow, startSeconds)\n        self.resultsDf['ChamberID'] = self.resultsDf['feedLogDate'] + \\\n            '_Chamber' + self.resultsDf['ID'].astype(str)\n        if str(monitorWindow)+'beforeFeedSpeed_mm/s_Mean' in self.resultsDf.columns:\n            self.resultsDf[['ChamberID', str(monitorWindow)+'beforeFeedSpeed_mm/s_Mean', 'duringFeedSpeed_mm/s_Mean',  str( \n                monitorWindow)+'afterFeedSpeed_mm/s_Mean']] = self.meanPeriSpeed[['ChamberID', str(monitorWindow)+'beforeFeedSpeed_mm/s_Mean', 'duringFeedSpeed_mm/s_Mean',  str( \n                monitorWindow)+'afterFeedSpeed_mm/s_Mean']]\n        else:\n            self.resultsDf = pd.merge(\n                self.meanPeriSpeed, self.resultsDf, how=\"outer\", on='ChamberID')\n        for c in self.resultsDf.columns:\n            if 'mm/s' not in c:\n                self.resultsDf[c].fillna(0, inplace=True)\n\n        self.monitorMin = str(int(monitorWindow/60))+' min'\n        self.outputPrefix = self.outputFolder+self.monitorMin\n\n        PeriFeedDiagonal = locoPlotters.plotPeriFeedDiagonal(self, monitorWindow)\n\n        pairedSpeedPlots, pairedSpeedConstrasts = locoPlotters.plotPairedSpeeds(self, monitorWindow)\n        return PeriFeedDiagonal, pairedSpeedPlots, pairedSpeedConstrasts\n\n\ndef calculateFallEvents(self, nstd=4, windowsize=1000, ewm1=12, ewm2=26, ewm3=9):\n        # added Jan 2022 to detect falls\n        print('Detecting Fall Events...')\n        falls, newCountLog = locoDataMunger.fallEvents(\n            self.countLogDf, nstd, windowsize, ewm1, ewm2, ewm3)\n        self.resultsDf['falls'] = np.nanmax(falls, axis=0)\n        self.countLogDf = newCountLog\n        print('Done')"
  },
  {
    "objectID": "locoUtilities.html",
    "href": "locoUtilities.html",
    "title": "loco_nbdev",
    "section": "",
    "text": "def makeOutputFolders(dataFolder):\n    filelist=os.listdir(dataFolder)\n    if 'output' not in filelist:\n        outputDir = dataFolder + 'output/'\n        os.mkdir(outputDir)\n    else:\n        outputDir = dataFolder + 'output/'\n    if 'chamberPlots' not in os.listdir(outputDir):\n        os.mkdir(outputDir + 'chamberPlots/')\n    return outputDir\n\n\ndef resampleCountLog(countLogDf, countLogName, resampleFrequencyInMs =50, longForm = False):\n    originalCountLogDf = countLogDf\n    resampleFrequency = str(resampleFrequencyInMs) + 'L'\n    startDateTimeStr = countLogName[9:28]\n    startDateTime = datetime.datetime.strptime(startDateTimeStr, '%Y-%m-%d_%H-%M-%S')\n    absStartTime = datetime.datetime(2000, 1, 1, 0, 0, 0)\n    countLogDfNewTime = countLogDf.copy()\n    countLogDfNewTime.loc[:, 'NewAbsoluteTime'] = pd.to_timedelta(countLogDf['Seconds'], unit='s')\n    countLogDfNewTime.loc[:, 'NewTime'] = startDateTime + pd.to_timedelta(countLogDf['Seconds'], unit='s')\n    if longForm:\n        countLogDfReIndexed=countLogDfNewTime.set_index(countLogDfNewTime['NewTime'])\n    else:\n        countLogDfReIndexed=countLogDfNewTime.set_index(absStartTime + countLogDfNewTime['NewAbsoluteTime'])\n    countLogDfResampled = countLogDfReIndexed.resample(resampleFrequency).agg(np.mean)\n    return countLogDfResampled, originalCountLogDf\n\n\ndef espressoSaveFig(fig, figName, figDate, figDirectory, pngDPI = 300, tp = True):\n    fig.savefig(figDirectory + figName + str(figDate)+'.png', transparent = tp, dpi = pngDPI,  bbox_inches='tight')\n    fig.savefig(figDirectory + figName + str(figDate)+'.svg')\n\n\ndef espressoWriteDictToCSV(filename, dict):\n    import csv\n    with open(filename, 'w') as csv_file:\n        writer = csv.writer(csv_file)\n        for key, value in dict.items():\n           writer.writerow([key, value])\n\n\ndef checkDabestVersion():\n    import dabest\n    s = dabest.__version__.split('.')\n    dabestVersion = float(s[0]+'.'+s[1]+s[2])\n    print('dabest version = ' + dabest.__version__)\n    return dabestVersion\n\n\ndef startProgressbar():\n    import sys\n    sys.stdout.write(\"\\n[\") \n\n  #  toolbar_width = 10\n  #  sys.stdout.write(\"[%s]\" % (\"-\" * toolbar_width))\n    sys.stdout.flush()\n  #  sys.stdout.write(\"\\b\" * (toolbar_width+1)) # return to start of line, after '['\n\ndef drawProgressbar():    \n    import sys    \n    sys.stdout.write(\"-\")\n    sys.stdout.flush()\n    \ndef endProgressbar():\n    import sys\n    sys.stdout.write(\"]\\n\") # this ends the progress bar"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()"
  },
  {
    "objectID": "plotTools.html",
    "href": "plotTools.html",
    "title": "loco_nbdev",
    "section": "",
    "text": "def correlationPlot(x, y, ax = None):\n    import scipy\n    if ax == None:\n        ax = plt.gca()\n    ax.plot(x, y, 'r.')\n    \n    r, p = scipy.stats.pearsonr(x, y)\n    print('pearson\\'r ' + str(r) +  ', p value = ' + str(p))\n    return ax, r, p\n\n\ndef setFont(fontSelection, fontSize, fontWeight = 'normal'):\n    import matplotlib as mpl\n    from matplotlib import rcParams\n    # mpl.font_manager._rebuild()\n    rcParams['font.family'] = 'sans-serif'\n    rcParams['font.sans-serif'] = [fontSelection]\n    rcParams['font.size'] = fontSize \n    rcParams['font.weight'] = fontWeight\n\n\ndef plotContrasts(df, y, colorBy, compareBy, groupBy = 'Temperature', reverseCompareBy = False, reverseGroupBy = False, customPalette = None, pairedState = False, fontSize = 14, plot_kwargs = dict()):\n    setFont('Source Sans Bold', fontSize)\n    groups = np.unique(df[groupBy].astype(str))\n    if reverseGroupBy:\n        groups = groups[::-1]\n\n    compares = np.unique(df[compareBy].astype(str))\n    if reverseCompareBy:\n        compares = compares[::-1]\n    df['newPlotColumn'] = df[groupBy].astype(str) + '  ' + df[compareBy]\n    idxList = np.atleast_2d(groups[0]+'  ' +compares)\n\n\n    for i in range(1, len(groups)):\n        idxList = np.append(idxList, [groups[i]+'  ' +compares], axis = 0)\n    idxTuple = tuple([tuple(l) for l in idxList])\n\n    \n    dabestContrastData = dabest.load(df,\n                           x='newPlotColumn', # the default for this test config is to group flies by genotype\n                           y=y,\n                           idx=idxTuple,\n                           paired=False\n                          )\n    dabestContrastFig = dabestContrastData.mean_diff.plot( color_col=colorBy, custom_palette = customPalette, **plot_kwargs)\n    print(dabestContrastData.hedges_g)\n    if len(np.unique(df[groupBy]))==1:\n        flatListIdxC = [item.split('  ')[1] for item in idxTuple]\n        flatListIdxG = [item.split('  ')[0] for item in idxTuple]\n    else:\n        flatListIdxC = [item.split('  ')[1] for t in idxTuple for item in t]\n        flatListIdxG = [item.split('  ')[0] for t in idxTuple for item in t]\n    print(flatListIdxC)\n    print(flatListIdxG)\n#     if np.max([len(item) for item in flatListIdxC])>4:\n#         dabestContrastFig.axes[0].set_xticklabels(flatListIdxC, rotation = 45, ha=\"right\")\n#     else:\n#         dabestContrastFig.axes[0].set_xticklabels(flatListIdxC, rotation = 0, ha=\"center\")\n        \n    ylim = dabestContrastFig.axes[0].get_ylim()\n    for i in range(0, len(groups)):\n        xpos = (len(compares)-1)/2 + (i)*len(compares)\n        dabestContrastFig.axes[0].text(xpos, ylim[1]*1.05, groups[i], ha=\"center\")\n        dabestContrastFig.tight_layout()\n        dabestContrastFig.axes[0].plot([0 + i*len(compares), len(compares)-1 + i*len(compares)], [ylim[1], ylim[1]], 'k')\n    \n    return dabestContrastFig, dabestContrastData\n\n\ndef savePlots(figure, fileName, figureID = '', fDPI = 300):\n    figure.savefig(fileName +figureID +'.png',transparent=False, bbox_inches='tight', dpi=fDPI, pad=0.1, w_pad=0.5, h_pad=1.0)\n    figure.savefig(fileName +figureID +'.svg', bbox_inches='tight', pad=0.1, w_pad=0.5, h_pad=1)\n#\n\n\ndef saveDabestData(contrast, fileName, exptDataSource, figureID = '', unit = ''):\n    \n    #2022/01/25 changed the format of output file added _summary\n    \n    mStats = contrast.mean_diff.results\n    gStats = contrast.hedges_g.results\n    meanDiffRounded = mStats.round(2)\n    hedgesGRounded = gStats.round(2)\n    meanDiffRounded.to_csv(fileName +figureID + '_meanDiff.csv')\n    hedgesGRounded.to_csv( fileName +figureID + '_hedgesG.csv')\n\n    meanDiffRounded['comparison_number'] = range(len(meanDiffRounded))\n    hedgesGRounded['comparison_number'] = range(len(hedgesGRounded))\n    resultsMerged = pd.merge(meanDiffRounded, hedgesGRounded, on='comparison_number')\n    resultsMerged.columns = resultsMerged.columns.str.replace('_x', '_MD')\n    resultsMerged.columns = resultsMerged.columns.str.replace('_y', '_HG')\n\n    results1 = pd.merge(meanDiffRounded[['control', 'test', 'control_N', 'test_N', 'comparison_number']] ,\n                        resultsMerged[['difference_MD', 'comparison_number','ci_MD', \n                                       'bca_low_MD', 'bca_high_MD',\n       'bca_interval_idx_MD', 'pct_low_MD', 'pct_high_MD',\n       'pct_interval_idx_MD',\n       'difference_HG', 'ci_HG', 'bca_low_HG', 'bca_high_HG',\n       'bca_interval_idx_HG', 'pct_low_HG', 'pct_high_HG',\n       'pct_interval_idx_HG']], on='comparison_number')\n    \n\n    summaryResults = pd.merge(results1, meanDiffRounded.iloc[:, 17:26], on = 'comparison_number')\n\n    cols = list(summaryResults)\n    # move the column to head of list using index, pop and insert\n    cols.insert(0, cols.pop(cols.index('comparison_number')))\n    summaryResults = summaryResults.loc[:, cols]\n    if figureID:\n        summaryResults['comparison_number'] =  figureID + '_' + summaryResults['comparison_number'].astype(str)\n    summaryResults.to_csv(fileName +figureID + '_summary.csv')\n    \n    \n    f= open(fileName+\"ES_Sentences.txt\",\"w+\")\n    print('Saving stats to ' + fileName +figureID +\"ES_Sentences.txt\")\n    f.writelines('Location of data: \\n' + exptDataSource + '\\n\\n\\n')\n    print('\\n' + figureID + '\\n\\n')\n    f.writelines('\\n' + figureID + '\\n\\n')\n\n    for i in range (0, len(mStats)):\n        if mStats.difference[i] >0:\n            comp = 'higher than '\n        else:\n            comp = 'lower than '\n\n        meanDiffSentence = 'Test group (\"' + mStats.loc[i, 'test'] \\\n            + '\", sample size ' + str(mStats.loc[i, 'test_N'])\\\n                + ') is ' + comp + 'control group (\"'   \\\n                    + mStats.loc[i, 'control'] + '\", sample size ' \\\n                        + str(mStats.loc[i, 'control_N'])+  ') by ' \\\n                            + str(np.abs(mStats.loc[i, 'difference'].round(2))) + ' ' + unit\\\n                                + ' ('+ str(mStats.loc[i, 'ci']) +'% CI = [' \\\n                                    + str(mStats.loc[i, 'bca_low'].round(2)) + ', ' \\\n                                        + str(mStats.loc[i, 'bca_high'].round(2)) + '] ' + unit + ', p-value = ' \\\n                                            + str(mStats.iloc[i, -2].round(3))+', g = ' + str(gStats.loc[i, 'difference'].round(2))\\\n                                                + ').\\nHypothesis test used is '\\\n                                                +' '.join(mStats.columns[-2].split('_')[1:3]) + '.\\n'\n                                                \n                                                \n                                                \n                                                \n        hedgesGSentence = 'Hedge\\'s g for this comparison is ' + str(gStats.loc[i, 'difference'].round(2)) + ' '\\\n            + '('+ str(gStats.loc[i, 'ci']) +'% CI = [' \\\n                + str(gStats.loc[i, 'bca_low'].round(2)) \\\n                    + ', ' + str(gStats.loc[i, 'bca_high'].round(2)) + '] '+unit+').\\n\\n'\n\n        print('Bootstrap '  + str(i+1))\n        print(meanDiffSentence)\n        print(hedgesGSentence)\n        \n        f.writelines('Bootstrap ' + str(i+1) + '\\n')\n        f.writelines(meanDiffSentence)\n        f.writelines(hedgesGSentence)\n    f.close()\n\n    return summaryResults"
  },
  {
    "objectID": "locoDataMunger.html",
    "href": "locoDataMunger.html",
    "title": "loco_nbdev",
    "section": "",
    "text": "def extractDateStr(s):\n    dateString = re.search(r'\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}', s).group()\n    dateTime = datetime.datetime.strptime(dateString, '%Y-%m-%d_%H-%M-%S')\n    return dateString, dateTime\n\n\ndef readMetaAndCount(dataFolder, companionEspObj,  startMin, endMin, initialResamplePeriod, smoothing, longForm=False):\n    filelist = os.listdir(dataFolder)\n    countLogList = [s for s in filelist if \"CountLog\" in s]\n    if countLogList:\n        countLogList = np.sort(countLogList)\n        print('countLog files found: \\n')\n        print(countLogList)\n    else:\n        print('Warning: no countLog files')\n        exit()\n    metaDataList = [s for s in filelist if \"MetaData\" in s]\n    if metaDataList:\n        metaDataList = np.sort(metaDataList)\n        print('\\nmetaData files found: \\n')\n        print(metaDataList)\n    else:\n        print('Warning: no metaData files')\n        exit()\n    portLocationsList = [s for s in filelist if \"PortLocations\" in s]\n    if portLocationsList:\n        portLocationsList = np.sort(portLocationsList)\n        print('portLocations files found: \\n')\n        print(portLocationsList)\n    else:\n        print('Warning: no portlocations files')\n        exit()\n\n    feedLogList = [s for s in filelist if \"FeedLog\" in s]\n    if feedLogList:\n        feedLogList = np.sort(feedLogList)\n        print('\\nfeedLog files found: \\n')\n        print(feedLogList)\n    else:\n        if companionEspObj:\n            feedLogList = np.unique([extractDateStr(i)[0]\n                                    for i in companionEspObj.flies.ChamberID])\n            print(feedLogList)\n\n        else:\n            print('Warning: no feedlog files')\n\n    experimentSummary = []\n    for i in range(len(countLogList)):\n        companionMetaData = metaDataList[np.argmin([np.abs(extractDateStr(\n            m)[1] - extractDateStr(countLogList[i])[1]) for m in metaDataList])]\n        companionPortLocations = portLocationsList[np.argmin([np.abs(extractDateStr(\n            m)[1] - extractDateStr(countLogList[i])[1]) for m in portLocationsList])]\n        companionFeedLog = [m for m in feedLogList if np.abs(extractDateStr(\n            m)[1] - extractDateStr(countLogList[i])[1]).total_seconds() < 15]\n        if companionFeedLog:\n            companionFeedLog = companionFeedLog[0]\n            companionFeedLogDate = extractDateStr(companionFeedLog)[0]\n        else:\n            companionFeedLog = 'N/A'\n            companionFeedLogDate = 'N/A'\n        experimentSummary.append({'countLogFile': countLogList[i],\n                                  'countLogDate': extractDateStr(countLogList[i])[0],\n                                  'metaDataFile': companionMetaData,\n                                  'metaDataDate': extractDateStr(companionMetaData)[0],\n                                  'portLocationsFile': companionPortLocations,                                  'countLogDate': extractDateStr(countLogList[i])[0],\n                                  'portLocationsDate': extractDateStr(companionPortLocations)[0],\n                                  'feedLogFile': companionFeedLog,\n                                  'feedLogDate': companionFeedLogDate\n                                  })\n\n    experimentSummary = pd.DataFrame(experimentSummary)\n\n# definition:\n#   LeftPortX = the centerline  of the left capillary\n#   LeftPortY = the bottom of the left feed port\n#   etc\n\n    bigPortLocationsDf = pd.DataFrame()\n    for dataSetNumber in range(0, len(portLocationsList)):\n        portLocationsDf = pd.read_csv(\n            dataFolder + portLocationsList[dataSetNumber])\n        portLocationsDf['Date'] = portLocationsList[dataSetNumber][14:33]\n        portLocationsDf['DateChamberID'] = portLocationsDf['Date'] + \\\n            '_Chamber' + (portLocationsDf.index+1).astype(str)\n        xconv = portLocationsDf.XmmPerPix[0]\n        yconv = portLocationsDf.YmmPerPix[0]\n        portLocationsDf['ChamberTopConv'] = (\n            portLocationsDf.ChamberBottom - portLocationsDf.ChamberTop) * yconv\n        portLocationsDf['ChamberBottomConv'] = (\n            portLocationsDf.ChamberBottom - portLocationsDf.ChamberBottom) * yconv\n        portLocationsDf['ChamberLeftConv'] = (\n            portLocationsDf.ChamberLeft - portLocationsDf.ChamberLeft) * xconv\n        portLocationsDf['ChamberRightConv'] = (\n            portLocationsDf.ChamberRight - portLocationsDf.ChamberLeft) * xconv\n        portLocationsDf['PortsMidpointXConv'] = (\n            portLocationsDf.PortsMidpointX - portLocationsDf.ChamberLeft) * xconv\n        portLocationsDf['LeftPortXConv'] = (\n            portLocationsDf.LeftPortX - portLocationsDf.ChamberLeft) * xconv\n        portLocationsDf['LeftPortYConv'] = (\n            portLocationsDf.ChamberBottom - portLocationsDf.LeftPortY) * yconv\n        portLocationsDf['RightPortXConv'] = (\n            portLocationsDf.RightPortX - portLocationsDf.ChamberLeft) * xconv\n        portLocationsDf['RightPortYConv'] = (\n            portLocationsDf.ChamberBottom - portLocationsDf.RightPortY) * yconv\n        meanLeftPort = [np.mean(portLocationsDf['LeftPortXConv']), np.mean(\n            portLocationsDf['LeftPortYConv'])]\n        portLocationsDf['LeftPortXConvDev'] = portLocationsDf['LeftPortXConv'] - meanLeftPort[0]\n        portLocationsDf['LeftPortYConvDev'] = portLocationsDf['LeftPortYConv'] - meanLeftPort[1]\n        bigPortLocationsDf = pd.concat(\n            [bigPortLocationsDf, portLocationsDf], axis=0)\n\n    bigCountLogDf = pd.DataFrame()\n    bigMetaDataDf = pd.DataFrame()\n    for dataSetNumber in range(0, len(countLogList)):\n        print(countLogList[dataSetNumber])\n        experimentEntry = experimentSummary.loc[experimentSummary['countLogFile']\n                                                == countLogList[dataSetNumber]]\n        companionMetaData = experimentEntry['metaDataFile'].iloc[0]\n        print(companionMetaData)\n        companionPortLocationsDf = bigPortLocationsDf.loc[bigPortLocationsDf.Date == extractDateStr(\n            experimentEntry['portLocationsFile'].iloc[0])[0]]\n        metaDataDf = pd.read_csv(dataFolder + companionMetaData)\n        reader = pd.read_csv(\n            dataFolder + countLogList[dataSetNumber], chunksize=(endMin+1) * 60 * 30)\n        countLogDfUnselected = reader.get_chunk()\n        expectedIDs = {int(re.search(r'Ch(.*)_Obj1_X', s).group(1))\n                       for s in countLogDfUnselected.filter(regex='Obj1_X').columns}\n        existingIDs = set(metaDataDf.ID)\n        diffID = expectedIDs - existingIDs\n        if len(diffID) > 0:\n            print('MetaData is missing IDs ' + str(np.sort(list(diffID))))\n        for id in diffID:\n            todrop = countLogDfUnselected.filter(regex='Ch'+str(id)).columns\n            countLogDfUnselected = countLogDfUnselected.drop(\n                todrop.tolist(), axis=1)\n        companionPortLocationsDf = companionPortLocationsDf.loc[companionPortLocationsDf.index.isin(\n            metaDataDf.index)]\n        countLogDfTrimmed = calculateSpeedinCountLog(\n            countLogDfUnselected, companionPortLocationsDf, smoothing)\n        countLogDfTimeBanded = countLogDfTrimmed.loc[(\n            countLogDfTrimmed.Seconds > startMin * 60) & (countLogDfTrimmed.Seconds < endMin * 60)]\n        metaDataDf.columns = metaDataDf.columns.str.replace(' ', '')\n        metaDataDf['Date'] = extractDateStr(countLogList[dataSetNumber])[0]\n        countLogDfNew, countLogDfOld = locoUtilities.resampleCountLog(\n            countLogDfTimeBanded, countLogList[dataSetNumber], initialResamplePeriod, longForm)\n        countLogDfNew = correctInPortData(countLogDfNew)\n\n        if longForm is False:\n            countLogDfNew.columns = countLogList[dataSetNumber][9:28] + \\\n                '_' + countLogDfNew.columns\n        if dataSetNumber == 0:\n            bigCountLogDf = countLogDfNew\n            bigMetaDataDf = metaDataDf\n        else:\n            if longForm:\n                bigCountLogDf = pd.concat(\n                    [bigCountLogDf, countLogDfNew], axis=0)\n            else:\n                bigCountLogDf = pd.concat(\n                    [bigCountLogDf, countLogDfNew], axis=1)\n                bigMetaDataDf = pd.concat([bigMetaDataDf, metaDataDf], axis=0)\n\n    bigMetaDataDf = bigMetaDataDf.reset_index(drop=True)\n    bigMetaDataDf['Genotype'] = bigMetaDataDf['Genotype'].str.lower()\n    bigMetaDataDf['Food1'] = bigMetaDataDf['Food1'].astype(str)\n    bigMetaDataDf['Food2'] = bigMetaDataDf['Food2'].astype(str)\n    bigMetaDataDf['Starvedhrs'] = bigMetaDataDf['Starvedhrs'].astype(str)\n    bigMetaDataDf = assignStatus(bigMetaDataDf)\n    return bigMetaDataDf, bigCountLogDf, bigPortLocationsDf, experimentSummary\n\n\ndef calculateSpeedinCountLog(countLogDf, companionPortLocationsDf, smoothing, speedThreshold=30, gaussianWindowSize=10, gaussianSTD=3):\n    xconv = companionPortLocationsDf.XmmPerPix[0]\n    yconv = companionPortLocationsDf.YmmPerPix[0]\n    cx = countLogDf.filter(regex='_X') * xconv\n    cy = countLogDf.filter(regex='_Y') * yconv\n    cv = countLogDf.filter(regex='_Vpix/s')\n    ct = countLogDf.filter(regex='Seconds')\n    X = cx.rename(columns=lambda x: ''.join(\n        [str(x).split('_')[0], '_', str(x).split('_')[1]]))\n    Y = cy.rename(columns=lambda x: ''.join(\n        [str(x).split('_')[0], '_', str(x).split('_')[1]]))\n    ctc = [companionPortLocationsDf.ChamberTopConv.values for i in range(\n        0, Y.shape[0])]\n    chamberTops = pd.DataFrame(ctc, columns=Y.columns)\n    Y = chamberTops - Y\n    if smoothing:\n        # smoothing X and Y\n        XX = X.rolling(gaussianWindowSize, win_type='gaussian').mean(\n            std=gaussianSTD)\n        YY = Y.rolling(gaussianWindowSize, win_type='gaussian').mean(\n            std=gaussianSTD)\n    else:\n        XX = X\n        YY = Y\n    deltaXX = np.diff(XX, axis=0)\n    deltaYY = np.diff(YY, axis=0)\n    deltaT = np.diff(ct, axis=0)\n    VV = (deltaXX**2+deltaYY**2)**0.5/deltaT\n    VV = pd.DataFrame(np.concatenate(\n        [np.zeros([1, VV.shape[1]]), VV]), columns=cv.columns)\n    VV = VV.rename(columns=lambda x: ''.join(\n        [str(x).split('_')[0], '_', str(x).split('_')[1]]))\n    for column in VV.columns:\n        VV[column] = intrapolateUnderThreshold(\n            VV.loc[:, column], speedThreshold)\n    Vy = deltaYY/deltaT\n    Vy = pd.DataFrame(np.concatenate(\n        [np.zeros([1, Vy.shape[1]]), Vy]), columns=cv.columns)\n    Vy = Vy.rename(columns=lambda x: ''.join(\n        [str(x).split('_')[0], '_', str(x).split('_')[1]]))\n    Vx = deltaXX/deltaT\n    Vx = pd.DataFrame(np.concatenate(\n        [np.zeros([1, Vx.shape[1]]), Vx]), columns=cv.columns)\n    Vx = Vx.rename(columns=lambda x: ''.join(\n        [str(x).split('_')[0], '_', str(x).split('_')[1]]))\n\n    lp = [companionPortLocationsDf.LeftPortYConv.values for i in range(\n        0, YY.shape[0])]\n    leftPort = pd.DataFrame(lp, columns=YY.columns)\n    rp = [companionPortLocationsDf.RightPortYConv.values for i in range(\n        0, YY.shape[0])]\n    rightPort = pd.DataFrame(rp, columns=YY.columns)\n    mpX = [companionPortLocationsDf.PortsMidpointXConv.values for i in range(\n        0, YY.shape[0])]\n    midpointX = pd.DataFrame(mpX, columns=YY.columns)\n\n    InLeftPort = (1*(YY > leftPort) + 1*(XX < midpointX)) == 2\n    InRightPort = (1*(YY > rightPort) + 1*(XX > midpointX)) == 2\n\n    XX = XX.rename(columns=lambda x: str(x)+'_X')\n    YY = YY.rename(columns=lambda x: str(x)+'_Y')\n    VV = VV.rename(columns=lambda x: str(x)+'_V')\n    Vy = Vy.rename(columns=lambda x: str(x)+'_vY')\n    Vx = Vx.rename(columns=lambda x: str(x)+'_vX')\n    InLeftPort = InLeftPort.rename(columns=lambda x: str(x)+'_InLeftPort')\n    InRightPort = InRightPort.rename(columns=lambda x: str(x)+'_InRightPort')\n    newCountLog = pd.concat([countLogDf.iloc[:, [0, 1, 2]],\n                            XX, YY, VV, Vy, Vx, InLeftPort, InRightPort], axis=1)\n    return newCountLog\n\n\ndef calculatePeriFeedLoco(countLogDf, companionPortLocationsDf, companionEspObj, exptSum, monitorWindow=120, startSeconds=0):\n\n    feedsRevisedDf = companionEspObj.feeds\n    feedsRevisedDf['startMonitorIdx'] = np.nan\n    feedsRevisedDf['startFeedIdx'] = np.nan\n    feedsRevisedDf['startFeedIdxRevised'] = np.nan\n    feedsRevisedDf['endFeedIdx'] = np.nan\n    feedsRevisedDf['endFeedIdxRevised'] = np.nan\n    feedsRevisedDf['endMonitorIdx'] = np.nan\n    feedsRevisedDf[str(monitorWindow)+'beforeFeedSpeed_mm/s'] = np.nan\n    feedsRevisedDf['duringFeedSpeed_mm/s'] = np.nan\n    feedsRevisedDf[str(monitorWindow)+'afterFeedSpeed_mm/s'] = np.nan\n    feedsRevisedDf['revisedFeedDuration_s'] = np.nan\n    feedsRevisedDf['countLogID'] = np.nan\n\n    feedsRevisedDf = feedsRevisedDf.drop(labels=feedsRevisedDf.loc[np.isnan(\n        feedsRevisedDf['FeedDuration_s'])].index, axis=0)\n\n    # setup toolbar\n\n    print('recalculating feed duration for feeds...')\n    locoUtilities.startProgressbar()\n    for i in feedsRevisedDf.index:\n        feed = feedsRevisedDf.loc[i]\n        if feed.RelativeTime_s > startSeconds:\n            chamberID = feed['ChamberID']\n            feedDate = extractDateStr(chamberID)[0]\n            # print(feedDate)\n            # print(exptSum.loc[exptSum['feedLogDate']==feedDate])\n            countDate = exptSum.loc[exptSum['feedLogDate']\n                                    == feedDate]['countLogDate'].iloc[0]\n            countLogObjID = countDate + '_Ch' + \\\n                chamberID.split('amber')[1]+'_Obj1'\n            y = countLogDf[countLogObjID+'_Y']\n            t = countLogDf[countDate+'_Seconds']\n            v = countLogDf[countLogObjID+'_V']\n            ploc = companionPortLocationsDf.loc[companionPortLocationsDf.DateChamberID == chamberID]\n            startFeedTime = feed['RelativeTime_s']\n            endFeedTime = feed['RelativeTime_s'] + feed['FeedDuration_s']\n            startFeedIdx = np.abs(t - startFeedTime).idxmin()\n            endFeedIdx = np.abs(t - endFeedTime).idxmin()\n            outPort = 1*(y[startFeedIdx:endFeedIdx].values -\n                         ploc.LeftPortYConv.values < 0)\n            longestFeedStretch = np.cumsum(\n                outPort) == np.bincount(outPort.cumsum()).argmax()\n            longestFeedStretchIdx = [\n                j for j, l in enumerate(longestFeedStretch) if l]\n            startFeedIdx1 = t.index[t.index.get_loc(\n                startFeedIdx)+longestFeedStretchIdx[0]]\n            endFeedIdx1 = t.index[t.index.get_loc(\n                startFeedIdx)+longestFeedStretchIdx[-1]]\n            startFeedTime1 = t[startFeedIdx1]\n            endFeedTime1 = t[endFeedIdx1]\n            startMonitorTime = np.max([0, startFeedTime1 - monitorWindow])\n            startMonitorIdx = np.abs(t - startMonitorTime).idxmin()\n            endMonitorTime = np.nanmin(\n                [np.nanmax(t.values), endFeedTime1 + monitorWindow])\n            endMonitorIdx = np.abs(t - endMonitorTime).idxmin()\n            feedsRevisedDf.loc[i, 'countLogID'] = countLogObjID\n            feedsRevisedDf.loc[i, 'startMonitorIdx'] = startMonitorIdx\n            feedsRevisedDf.loc[i, 'startFeedIdx'] = startFeedIdx\n            feedsRevisedDf.loc[i, 'startFeedIdxRevised'] = startFeedIdx1\n            feedsRevisedDf.loc[i, 'endFeedIdx'] = endFeedIdx\n            feedsRevisedDf.loc[i, 'endFeedIdxRevised'] = endFeedIdx1\n            feedsRevisedDf.loc[i, 'endMonitorIdx'] = endMonitorIdx\n            feedsRevisedDf.loc[i,\n                               'revisedFeedDuration_s'] = endFeedTime1 - startFeedTime1\n            vb = np.nanmean(v[startMonitorIdx:startFeedIdx1])\n            vd = np.nanmean(v[startFeedIdx1:endFeedIdx1])\n            va = np.nanmean(v[endFeedIdx1:endMonitorIdx])\n            feedsRevisedDf.loc[i, str(monitorWindow) +\n                               'beforeFeedSpeed_mm/s'] = vb\n            feedsRevisedDf.loc[i, 'duringFeedSpeed_mm/s'] = vd\n            feedsRevisedDf.loc[i, str(monitorWindow) +\n                               'afterFeedSpeed_mm/s'] = va\n            feedsRevisedDf.loc[i, str(\n                monitorWindow)+'duringPercSpeedGain'] = ((vd - vb)/(vb))*100\n            feedsRevisedDf.loc[i, str(monitorWindow) +\n                               'afterPercSpeedGain'] = ((va - vb)/vb)*100\n            locoUtilities.drawProgressbar()\n    locoUtilities.endProgressbar()\n\n    feedsRevisedDf['revisedFeedDuration_min'] = feedsRevisedDf['revisedFeedDuration_s']/60\n    grouped_df = feedsRevisedDf.groupby(['ChamberID', 'countLogID'])\n    mean_df = grouped_df.mean()\n    mean_df.reset_index(inplace=True)\n    total_df = grouped_df.sum()\n    total_df.reset_index(inplace=True)\n    feedResults = pd.merge(mean_df, total_df, how='outer',\n                           on='ChamberID', suffixes=(\"_Mean\", \"_Total\"))\n    feedResults = feedResults.drop(columns=['countLogID_Total', 'FeedSpeed_nl/s_Total', 'RelativeTime_s_Total',  'Starved hrs_Total', 'AverageFeedSpeedPerFly_µl/s_Total', str(\n        monitorWindow)+'beforeFeedSpeed_mm/s_Total', 'duringFeedSpeed_mm/s_Total', str(monitorWindow)+'afterFeedSpeed_mm/s_Total'])\n    feedResults['duringBeforeSpeedRatio'] = feedResults['duringFeedSpeed_mm/s_Mean'] / \\\n        feedResults[str(monitorWindow)+'beforeFeedSpeed_mm/s_Mean']\n    feedResults['afterBeforeSpeedRatio'] = feedResults[str(\n        monitorWindow)+'afterFeedSpeed_mm/s_Mean'] / feedResults[str(monitorWindow)+'beforeFeedSpeed_mm/s_Mean']\n    feedVolColumns = [s.replace('_X', '_feedVol_nl')\n                      for s in countLogDf.filter(regex='_X').columns]\n    feedCountColumns = [s.replace('_X', '_feedCount')\n                        for s in countLogDf.filter(regex='_X').columns]\n    feedDurationColumns = [s.replace(\n        '_X', '_feedRevisedDuration_s') for s in countLogDf.filter(regex='_X').columns]\n    cumVolColumns = [s.replace('_X', '_cumVol')\n                     for s in countLogDf.filter(regex='_X').columns]\n    countLogDfNew = countLogDf\n    countLogDfNew.drop(list(countLogDfNew.filter(\n        regex='_feedVol_nl')), axis=1, inplace=True)\n    countLogDfNew.drop(list(countLogDfNew.filter(\n        regex='_feedCount')), axis=1, inplace=True)\n    countLogDfNew.drop(list(countLogDfNew.filter(\n        regex='_feedRevisedDuration_s')), axis=1, inplace=True)\n    countLogDfNew.drop(list(countLogDfNew.filter(\n        regex='_cumVol')), axis=1, inplace=True)\n    countLogDfNew = pd.concat([countLogDf, pd.DataFrame(\n        0, index=countLogDf.index, columns=feedVolColumns + feedCountColumns + feedDurationColumns)], axis=1)\n    print('putting feeds back into countlog...')\n    locoUtilities.startProgressbar()\n    for i in feedsRevisedDf.index:\n        countLogID = feedsRevisedDf.loc[i, 'countLogID']\n        endFeedIdxRevised = feedsRevisedDf.loc[i, 'endFeedIdxRevised']\n        countLogDfNew.loc[endFeedIdxRevised, countLogID +\n                          '_feedVol_nl'] = feedsRevisedDf.loc[i, 'FeedVol_nl']\n        countLogDfNew.loc[endFeedIdxRevised, countLogID+'_feedCount'] = 1\n        countLogDfNew.loc[endFeedIdxRevised, countLogID +\n                          '_feedRevisedDuration_s'] = feedsRevisedDf.loc[i, 'revisedFeedDuration_s']\n        # print(countLogDfNew.loc[endFeedIdxRevised])\n        # print(feedsRevisedDf.loc[i, 'revisedFeedDuration_s'])\n        # print(countLogDfNew.loc[endFeedIdxRevised, countLogID+'_feedRevisedDuration'])\n    # plt.plot(countLogDfNew[countLogDfNew.filter('_feedRevisedDuration').columns].fillna(0), 'o')\n        locoUtilities.drawProgressbar()\n    locoUtilities.endProgressbar()\n\n    durCols = countLogDfNew.filter('_feedRevisedDuration').columns\n    countLogDfNew[durCols] = countLogDfNew[durCols].fillna(0)\n    cumFeedVol = countLogDfNew.filter(regex='_feedVol').cumsum()\n    # print(cumFeedVol.columns)\n    # print(cumVolColumns)\n    cumFeedVol.columns = cumVolColumns\n    countLogDfNew = pd.concat([countLogDfNew, cumFeedVol], axis=1)\n    maxSpeed = np.ceil(np.nanmax(feedResults[[str(monitorWindow)+'beforeFeedSpeed_mm/s_Mean',\n                                              'duringFeedSpeed_mm/s_Mean', str(monitorWindow)+'afterFeedSpeed_mm/s_Mean']]))\n\n    return feedsRevisedDf, countLogDfNew, feedResults, maxSpeed\n\n\ndef labelStretches(vector):\n    vectorCopy = vector\n    invVector = 1 - vector\n    IVcumsum = invVector.cumsum()\n    IVbin = np.bincount(IVcumsum)\n    IVbinS = IVbin[IVbin > 1]\n    IVbinSU = np.unique(IVbinS)\n    idxMat = pd.DataFrame(columns=['sIdx', 'inc'])\n    n = 0\n    import time\n        \n\n    for j in range(0, len(IVbinSU)):\n        startIdx = [i for i, ivb in enumerate(IVbin == IVbinSU[j]) if ivb]\n        t1 = time.time()\n        print('start')\n     \n        for k in startIdx:\n            idxMat.loc[n, ['sIdx', 'inc']] = [k, IVbinSU[j]]\n            n = n+1\n    idxMat = idxMat.astype(int)\n    idxMat = idxMat.sort_values(by='sIdx').reset_index(drop=True)\n    t2 = time.time()\n    print(t2-t1)\n    print(idxMat)\n    if len(idxMat) > 0:\n        idxMat['inc'][1::] = idxMat['inc'][1::]-1\n        idxMat['cumInc'] = idxMat['inc'].cumsum()\n        curr = [idxMat.loc[i]['sIdx']+idxMat.loc[i-1]['cumInc']\n                for i in idxMat.index[1::]]\n        curr.append(idxMat.loc[0, 'sIdx'])\n        curr.sort()\n        idxMat['currIdx'] = curr\n\n        for i in idxMat.index:\n            # print(i)\n            vectorCopy[idxMat.loc[i, 'currIdx']:idxMat.loc[i, 'currIdx']+idxMat.loc[i, 'inc']] = i+1\n    else:\n        vectorCopy = vector\n    t3 = time.time()\n    print(t3-t2)\n\n    return vectorCopy, idxMat\n\n\ndef correctInPortData(countLogDf):\n    for column in countLogDf.filter(regex='InLeftPort').columns:\n        column\n        x = countLogDf[column] > 0\n        v, m = labelStretches(x)\n        countLogDf[column] = v\n    for column in countLogDf.filter(regex='InRightPort').columns:\n        x = countLogDf[column] > 0\n        v, m = labelStretches(x)\n        countLogDf[column] = v\n    return countLogDf\n\n\ndef intrapolateUnderThreshold(s, th):\n    sOverTh = np.array([i for i, x in enumerate(s) if x != 'NaN' and x > th])\n    # print('removed indices ' + str(sOverTh))\n    s[sOverTh] = 'NaN'\n    s = np.array(s, dtype=np.float64)\n    nans, interpInd = np.isnan(s), lambda z: z.nonzero()[0]\n    s[nans] = np.interp(interpInd(nans), interpInd(~nans), s[~nans])\n    return s\n\n\ndef assignStatus(metaDataDf):\n    if 'Status' not in metaDataDf.columns:\n        metaDataDf.insert(1, 'Status', metaDataDf.Genotype, True)\n        metaDataDfCopy = metaDataDf.copy()\n        TestInd = [i for i, s in enumerate(\n            metaDataDf.Genotype) if 'w1118' not in s]\n        metaDataDfCopy['Status'] = 'Ctrl'\n        metaDataDfCopy.loc[TestInd, 'Status'] = 'Test'\n        metaDataDf = metaDataDfCopy\n    return metaDataDf\n\n\ndef fallEvents(countLogDf, nstd=4, windowsize=1000, ewm1=12, ewm2=26, ewm3=9):\n    # added Jan 2022 to detect falls\n    yy = countLogDf.filter(regex='_Y')\n    vx = countLogDf.filter(regex='_vX')\n    vy = countLogDf.filter(regex='_vY')\n    omega = pd.DataFrame(data=np.arctan(vx.values/vy.values), index=vy.index,\n                         columns=[c.split('_v')[0] + '_AV' for c in vy.columns])\n\n    exp1 = vy.ewm(span=ewm1, adjust=False).mean()\n    exp2 = vy.ewm(span=ewm2, adjust=False).mean()\n    macd = exp1-exp2\n    exp3 = macd.ewm(span=ewm3, adjust=False).mean()\n    a = np.zeros(vy.shape)\n    aa = np.zeros(vy.shape)\n    b = []\n    locoUtilities.startProgressbar()\n    for i in range(0, macd.shape[1]):\n        print(i)\n\n        a[:, i], b = labelStretches(macd.iloc[:, i]-exp3.iloc[:, i] < -0.025)\n        n = 1\n        for j in range(0, len(b)):\n            segstart = b.currIdx[j]\n            segend = b.currIdx[j]+b.inc[j]\n            speedthreshold = - np.nanmean(np.abs(vy.iloc[segstart-windowsize:segend+windowsize, i]))-np.nanstd(\n                np.abs(vy.iloc[segstart-windowsize:segend+windowsize, i]))*nstd\n            if len(vy.iloc[segstart: segend+1, i]) > 0:\n                if np.nanmin(vy.iloc[segstart: segend+1, i].values) < speedthreshold and np.nanmax(yy.iloc[segstart: segend+1, i].values) - np.nanmin(yy.iloc[segstart: segend, i].values) > 0.5:\n                    aa[segstart:segend, i] = n\n                    n = n + 1        \n        locoUtilities.drawProgressbar()\n    locoUtilities.endProgressbar()\n\n    falls = pd.DataFrame(data=aa, index=vy.index, columns=[\n                         c.split('_v')[0] + '_Falls' for c in vy.columns])\n    countLogDf.drop(list(countLogDf.filter(regex='_AV')), axis=1, inplace=True)\n    countLogDf.drop(list(countLogDf.filter(regex='_Falls')),\n                    axis=1, inplace=True)\n\n    newCountLog = pd.concat(\n        [countLogDf.iloc[:, [0, 1, 2]], omega, falls], axis=1)\n    newCountLog = pd.concat([countLogDf, omega, falls], axis=1)\n    return falls, newCountLog, macd"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "loco_nbdev",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "loco_nbdev",
    "section": "Install",
    "text": "Install\npip install loco_nbdev"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "loco_nbdev",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "locoPlotters.html",
    "href": "locoPlotters.html",
    "title": "loco_nbdev",
    "section": "",
    "text": "def espressoChamberStyling(ax, axisSwitch = 'off'):\n    ax.set_aspect('equal')\n    ax.spines['bottom'].set_color('gray')\n    ax.spines['top'].set_color('gray')\n    ax.spines['right'].set_color('gray')\n    ax.spines['left'].set_color('gray')\n    ax.axis(axisSwitch)\n    ax.set_xlim(0, 13)\n    ax.set_ylim(-2, 18)\n\n\ndef espressoCreatePalette(items, testColor = 'crimson'):\n    wes_palette, wes_colors = createWesAndersonPalette()\n    keys = np.sort(np.unique(items))[::-1]\n    colorPalette = {}\n    colors = wes_palette\n    n=0\n    for i in range(len(keys)):\n        if 'gal4' in keys[i]:\n            if 'w1118' in keys[i]:\n                colorPalette[keys[i]] = wes_colors['black']\n                continue\n            if 'acr' in keys[i]:\n                colorPalette[keys[i]] = wes_colors['cyan']\n                continue\n            if 'chrimson' in keys[i]:\n                colorPalette[keys[i]] = wes_colors['crimson']\n                continue\n            if 'tetx' in keys[i]:\n                colorPalette[keys[i]] = wes_colors['eggplant']\n                continue\n        if 'ms' in keys[i]:\n            if 'w1118' in keys[i]:\n                colorPalette[keys[i]] = wes_colors['black']\n                continue\n            if 'cas' in keys[i]:\n                colorPalette[keys[i]] = wes_colors['cyan']\n                continue\n        elif 'Ctrl' in keys[i]:\n            colorPalette[keys[i]] = wes_colors['black']\n            continue\n        elif 'Test' in keys[i]:\n            colorPalette[keys[i]] = wes_colors[testColor]\n            continue\n        elif 'Light On' in keys[i]:\n            colorPalette[keys[i]] = wes_colors[testColor]\n            continue\n        elif 'Light Off' in keys[i]:\n            colorPalette[keys[i]] = wes_colors['black']\n            continue\n        elif keys[i] == 'F':\n            colorPalette[keys[i]] = wes_colors['hotpink']\n            continue\n        elif keys[i] == 'M':\n            colorPalette[keys[i]] = wes_colors['lakeblue']\n            continue\n        elif keys[i] == 'VF':\n            colorPalette[keys[i]] = wes_colors['eggplant']\n            continue\n        else:\n            colorPalette[keys[i]] = colors[n]\n            n += 1\n    return colorPalette\n\n\ndef espressoPlotTracking(X, Y, flyName, colorPalette):\n    plt.plot(X, Y, linewidth = 0.5, color = colorPalette[flyName])\n    # plt.plot([7, 7], [0, 19], linewidth = 0.5, color = 'r')\n    # plt.plot([0, 15], [12, 12], linewidth = 0.5, color = 'r')\n\n\ndef espressoPlotHeatmap(X, Y, flyGenotype, colorPalette):\n    import matplotlib.colors as mcolors\n    # plt.hist2d(X[~np.isnan(X)],Y[~np.isnan(Y)], bins=[12, 20],cmap=plt.cm.bone, range=np.array([(0, 13), (-1, 18)]), norm=mcolors.PowerNorm(0.6))\n    plt.hist2d(X[~np.isnan(X)],Y[~np.isnan(Y)], bins=[12, 20],cmap=plt.cm.bone, range=np.array([(0, 13), (-1, 18)]))\n\n\ndef espressoPlotMeanHeatmaps(espLocoObj, binSize,row, col, reverseRows, reverseCols, verbose, heatmapCMap, smooth):\n    from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n    from astropy.convolution import convolve, Gaussian2DKernel\n\n    XX = espLocoObj.countLogDf.filter(regex = '_X')\n    YY = espLocoObj.countLogDf.filter(regex = '_Y')\n    XXCorrected = np.zeros(XX.shape)\n    YYCorrected = np.zeros(YY.shape)\n    meanLPX = np.mean(espLocoObj.portLocationsDf['LeftPortXConv'])\n    meanLPY = np.mean(espLocoObj.portLocationsDf['LeftPortYConv'])\n\n    for i in range(XX.shape[1]):\n        XXCorrected[:, i]=XX.iloc[:, i]-espLocoObj.portLocationsDf['LeftPortXConvDev'].iloc[i]\n        YYCorrected[:, i]=YY.iloc[:, i]-espLocoObj.portLocationsDf['LeftPortYConvDev'].iloc[i]    \n    H = []\n    xCeil = np.ceil(np.max(np.max(XX)))\n    xFloor = np.floor(np.min(np.min(XX)))\n    yCeil = np.ceil(np.max(np.max(YY)))\n    yFloor = np.floor(np.min(np.min(YY)))\n    xedges = np.arange(xFloor, xCeil, binSize)\n    yedges = np.arange(yFloor, yCeil, binSize)\n    numlist = list(range(0, len(espLocoObj.metaDataDf)))\n    smallHeatmapFigs = plt.figure (num = 1, figsize = [5, np.ceil((len(numlist)+1)/5)*0.8])\n    n = 1\n    for j in numlist:\n    #        plotFunc(X.iloc[:, j-1], Y.iloc[:, j-1], flyGenotype, colorPalette)\n        # print(str(j) + ' ' + espLocoObj.metaDataDf.Genotype[j])\n        X = XXCorrected[:, j]\n        Y = YYCorrected[:, j]\n        h, xedges, yedges = np.histogram2d(X[~np.isnan(X)], Y[~np.isnan(Y)], bins = [xedges, yedges])\n        extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n        if verbose:\n            plt.subplot(np.ceil((len(numlist)+1)/5), 5, n)\n            plt.imshow(h.T, extent=extent, origin='lower', cmap = heatmapCMap)\n        n += 1\n        H.append(h)\n    Hall = np.dstack(H)\n    Hall = Hall/50/60 #originally resampled at 50ms and to convert to minute from second/60\n    listOfPlots, gp, custom_palette = subplotRowColColor(espLocoObj.metaDataDf, None, row, col, reverseRows, reverseCols)\n    nr, nc = listOfPlots[-1][0][0:2]\n    meanHeatmapFig, axes = plt.subplots(nrows=nr + 1, ncols=nc + 1, figsize = (3 * (nc + 1), 4 * (nr + 1)), squeeze = False)\n    images = []\n    for i in range(0, len(listOfPlots)):\n        # print(listOfPlots[i])\n        ro, co = listOfPlots[i][0][0:2]\n        # print(listOfPlots[i][0][0:2])\n        name = listOfPlots[i][1]\n        # print(name)\n        ind = gp[name]\n        Hmean = np.mean(Hall[:, :, ind], axis = 2)\n        if smooth:\n            images.append(axes[ro, co].imshow(convolve(Hmean.T, Gaussian2DKernel(x_stddev=smooth, y_stddev=smooth)), extent=extent, origin='lower', cmap = heatmapCMap))\n        else:\n            images.append(axes[ro, co].imshow(Hmean.T, extent=extent, origin='lower', cmap = heatmapCMap))\n        axes[ro, co].set_title(name[0]+ '\\n' + name[1])\n        axes[ro, co].label_outer()\n        setAxesTicks(axes[ro, co], False)\n        axes[ro, co].plot([meanLPX-1.5 , meanLPX+1.5], [meanLPY, meanLPY], color = 'y', linewidth = 2)\n    # plt.text(10, 16.5, '2 mm', color = 'w', ha = 'center')\n    plt.plot([9, 11], [yFloor+0.5, yFloor+0.5], color = 'w', linewidth = 2)\n    # left = np.sum(np.sum(Hall[4:9, 21:25, :], axis = 0), axis = 0)\n    # right = np.sum(np.sum(Hall[10:15, 21:25, :], axis = 0), axis = 0)\n    # bottom = np.sum(np.sum(Hall[4:15, 4:7, :], axis = 0), axis = 0)\n    # resultsDf = espLocoObj.resultsDf\n\n    # resultsDf['left'] = left\n    # resultsDf['right'] = right\n    # resultsDf['bottom'] = bottom\n    # resultsDf['LR Preference'] = (resultsDf['left']- resultsDf['right'])/ (resultsDf['right']+resultsDf['left'])\n    # resultsDf['TB Preference'] = (resultsDf['right'] + resultsDf['left'] - resultsDf['bottom'])/ (resultsDf['bottom']+resultsDf['right']+resultsDf['left'])\n    vmin = min(image.get_array().min() for image in images)\n    vmax = max(image.get_array().max() for image in images)\n    norm = colors.Normalize(vmin=vmin, vmax=vmax)\n    for im in images:\n        im.set_norm(norm)\n    # axins = inset_axes(axes[-1, -1],\n    #                width=\"5%\",  # width = 5% of parent_bbox width\n    #                height=\"100%\",  # height : 50%\n    #                location = 'left',  \n    #                # orientation = 'horizontal',\n    #                # bbox_to_anchor=(1.05, 0., 1, 1),\n    #                # bbox_transform=axes[-1, -1].transAxes,\n    #                borderpad=0,\n    #                )\n    # from mpl_toolkits.axes_grid1 import make_axes_locatable\n\n    # divider = make_axes_locatable(axes[-1, -1])\n    # cax = divider.new_vertical(size='5%', pad=0.1, pack_start = True)\n    # meanHeatmapFig.add_axes(cax)\n    cax = meanHeatmapFig.add_axes([axes[0, 0].get_position().x0, 0.08, axes[-1, -1].get_position().x1-axes[0, 0].get_position().x0, 0.02])\n    # meanHeatmapFig.colorbar(images[-1], cax=axins, ticks=[0, 5, 10, 15, 20])\n    def update(changed_image):\n        for im in images:\n            if (changed_image.get_cmap() != im.get_cmap()\n                    or changed_image.get_clim() != im.get_clim()):\n                im.set_cmap(changed_image.get_cmap())\n                im.set_clim(changed_image.get_clim())\n    for im in images:\n        im.callbacksSM.connect('changed', update)\n    meanHeatmapFig.colorbar(images[-1], cax=cax, orientation = 'horizontal')\n    plt.show()\n    meanHeatmapFileName = 'meanHeatmapFig'+ '_' + str(col) + '_' + str(row) + str(espLocoObj.startMin) + '-' + str(espLocoObj.endMin) + 'min'\n    locoUtilities.espressoSaveFig(meanHeatmapFig, meanHeatmapFileName, espLocoObj.metaDataDf.Date[0], espLocoObj.outputFolder)\n    # locoUtilities.espressoWriteDictToCSV(espLocoObj.outputFolder+meanHeatmapFileName+'_ConditionsTable.csv', gp)\n    if verbose:\n        return meanHeatmapFig, Hall, images, smallHeatmapFigs\n    else:\n        return meanHeatmapFig, Hall, images\n\n\ndef plotBoundedLine(x, Y, ax=None, c = 'k', resamplePeriod = '200s'):\n    if ax is None:\n        ax = plt.gca()\n    if resamplePeriod:\n        Y = Y.resample(resamplePeriod).agg(np.mean)\n        x = x.resample(resamplePeriod).agg(np.mean)\n    y = np.nanmean(Y, axis = 1)\n    ci = np.nanstd(Y, axis = 1)/(np.sqrt(Y.shape[1]))*1.96\n    ax.meanLine = ax.plot(x, y, color = c)\n    ax.ciBound =  ax.fill_between(x, y+ci,  y-ci, color = c, alpha=0.2, label='_nolegend_')\n    setAxesTicks(ax, True, gridState = False)\n    return(ax)\n\n\ndef putThingsInToChamberSubplot(countLogDf, metaDataDf, portLocationsDf, customPalette, ncol, plotFunc = espressoPlotTracking,   showID = False):\n    noOfRows=int(np.ceil(len(metaDataDf)/ncol))\n    chamberSmalls, axarr = plt.subplots(noOfRows, ncol, figsize = [ncol/1.5, noOfRows])\n    metaDataDf = metaDataDf.reset_index()\n    portLocationsDf = portLocationsDf.reset_index()\n    \n    for j in metaDataDf.index:\n        id = metaDataDf.loc[j, 'ID']\n        col = np.mod(id-1, ncol)\n        row = int((id - col)/ncol)\n        chamberSmalls.sca(axarr[row, col])\n        if customPalette:\n            colorPalette = customPalette\n        else:\n            colorPalette = espressoCreatePalette(metaDataDf['Genotype'])\n        flyGenotype = metaDataDf['Genotype'][j]\n        X = countLogDf.filter(regex = '_X')\n        Y = countLogDf.filter(regex = '_Y')\n#        plotFunc(X.iloc[:, j-1], Y.iloc[:, j-1], flyGenotype, colorPalette)\n        # print(colorPalette)\n        plotFunc(X.iloc[:, j], Y.iloc[:, j], flyGenotype, colorPalette)\n#        axarr[row, col].set_title(flyGenotype)\n        plotChamber(portLocationsDf.iloc[j], axarr[row, col])\n        if showID:\n            plt.title(metaDataDf.loc[j, 'ID'])\n    chamberSmalls.suptitle(metaDataDf.loc[0, 'Date'] + ' ' + str(metaDataDf.loc[0, 'Temperature']) )\n    chamberSmalls.tight_layout()\n    chamberSmalls.subplots_adjust(\n                    wspace=0.02, \n                    hspace=0.0001)\n\n    for row in range(0, axarr.shape[0]):\n        for col in range(0, axarr.shape[1]):\n            espressoChamberStyling(axarr[row, col])\n    return chamberSmalls, axarr\n#\n\n\ndef plotChamber(ploc, ax):\n    chamberLeft = ploc.ChamberLeftConv        \n    chamberRight = ploc.ChamberRightConv                      \n    chamberTop = ploc.ChamberTopConv                      \n    chamberBottom = ploc.ChamberBottomConv                      \n    leftPortX = ploc.LeftPortXConv\n    leftPortY = ploc.LeftPortYConv\n    rightPortX = ploc.RightPortXConv\n    rightPortY = ploc.RightPortYConv\n    rectangle = [(chamberLeft, chamberTop), (chamberRight, chamberTop), (chamberRight, chamberBottom), (chamberLeft, chamberBottom)]\n    ax.plot(*zip(*(rectangle+rectangle[:1])), 'lightgray', linewidth = 0.2)\n    ax.axis('equal')\n    if ploc.LeftPortEnabled:\n        ll, = ax.plot([leftPortX - 1.5, leftPortX + 1.5], [leftPortY, leftPortY], 'seagreen', linewidth = 0.3, alpha = 0.3, )\n        ll.set_solid_capstyle('round')\n\n    if ploc.RightPortEnabled:\n        lr, = ax.plot([rightPortX - 1.5, rightPortX + 1.5], [rightPortY, rightPortY], 'seagreen', linewidth = 0.3, alpha = 0.3, )\n        lr.set_solid_capstyle('round')\n    # return ax, ((leftPortX, leftPortY), (rightPortX, rightPortY))\n    return\n\n\ndef subplotRowColColor(metaDataDf, colorBy, row, col, reverseRows, reverseCols):\n    m = metaDataDf\n    m = m.applymap(str)\n    if row == None:\n        m['row'] = ' '\n        row = 'row'\n    if col == None:\n        m['col'] = ' '\n        col = 'col'\n    if colorBy == None:\n        m['colorBy'] = ' '\n        colorBy = 'colorBy'\n    gp = m.groupby([row, col, colorBy]).groups\n    testGenotypeColor = 'lakeblue'\n    if m.Status.str.contains('Test').sum()>0:\n        testGenotypeName = np.unique(m.loc[m['Status'] == 'Test', 'Genotype'])[0]\n        if 'chrimson' in testGenotypeName or 'csch' in testGenotypeName:\n            testGenotypeColor = 'crimson'\n        elif 'acr' in testGenotypeName:\n            testGenotypeColor = 'cyan'\n        elif 'tetx' in testGenotypeName:\n            testGenotypeColor = 'eggplant'\n        elif 'cas' and 'ms' in testGenotypeName:\n            testGenotypeColor = 'cyan'\n    custom_palette = espressoCreatePalette(m[colorBy], testColor = testGenotypeColor)\n    if row == 'Temperature':\n        uniqueRows = np.sort(np.unique(m[row]))\n    else:\n        uniqueRows = np.sort(np.unique(m[row]))[::-1]\n    w1118InUniqueRows = ['w1118' not in uniqueRows[i] for i in range(len(uniqueRows))]\n    newind = np.argsort(w1118InUniqueRows)\n    uniqueRows = uniqueRows[newind]\n    if col == 'Temperature':\n        uniqueCols = np.sort(np.unique(m[col]))\n    else:\n        uniqueCols = np.sort(np.unique(m[col]))[::-1]\n\n    w1118InUniqueCols = ['w1118' not in uniqueCols[i] for i in range(len(uniqueCols))]\n    newind = np.argsort(w1118InUniqueCols)\n    uniqueCols = uniqueCols[newind]\n    if colorBy == 'Temperature':\n        uniqueColors = np.sort(np.unique(m[colorBy]))\n    else:\n        uniqueColors = np.sort(np.unique(m[colorBy]))[::-1]\n    w1118InUniqueColors = ['w1118' not in uniqueColors[i] for i in range(len(uniqueColors))]\n    newind = np.argsort(w1118InUniqueColors)\n    uniqueColors = uniqueColors[newind]\n    if reverseRows:\n        uniqueRows = uniqueRows[::-1]\n    if reverseCols:\n        uniqueCols = uniqueCols[::-1]\n\n    listOfPlotsUnfiltered = [((i, j, k), (r, c, cl)) for i, r in enumerate(uniqueRows) for j, c in enumerate(uniqueCols) for k, cl in enumerate(uniqueColors)]\n    listOfPlots = [i for i in listOfPlotsUnfiltered if i[1] in gp.keys()]\n    return listOfPlots, gp, custom_palette\n\n\ndef plotPeriFeedDiagonal(locoObj, monitorWindow):\n    print('plotting PeriFeedDiagonal')\n\n    PeriFeedDiagonal = plt.figure(figsize=(5, 5))\n    plt.plot([0, locoObj.maxSpeed], [0, locoObj.maxSpeed], 'lightgray')\n    plt.plot(locoObj.meanPeriSpeed[str(monitorWindow)+'beforeFeedSpeed_mm/s_Mean'],\n             locoObj.meanPeriSpeed['duringFeedSpeed_mm/s_Mean'], '.', c='steelblue', label='Speed during feed')\n    plt.plot(locoObj.meanPeriSpeed[str(monitorWindow)+'beforeFeedSpeed_mm/s_Mean'], locoObj.meanPeriSpeed[str(monitorWindow) +\n             'afterFeedSpeed_mm/s_Mean'], '.', c='orangered', label='Speed ' + locoObj.monitorMin + ' after feed')\n    plt.xlabel('Speed Before Feed (mm/s)')\n    plt.xlim(0, locoObj.maxSpeed)\n    plt.ylim(0, locoObj.maxSpeed)\n    plt.legend()\n    locoUtilities.espressoSaveFig(\n        PeriFeedDiagonal, locoObj.monitorMin+'PeriFeedDiagonal', locoObj.metaDataDf.Date[0], locoObj.outputFolder)\n    return PeriFeedDiagonal\n\n\ndef plotPairedSpeeds(locoObj, monitorWindow):\n    print('plotting pairedSpeedPlots')\n\n    speedMatrix = locoObj.resultsDf[['ChamberID', 'Genotype', 'Status', 'Temperature', str(\n    monitorWindow) + 'beforeFeedSpeed_mm/s_Mean', 'duringFeedSpeed_mm/s_Mean', str(monitorWindow) + 'afterFeedSpeed_mm/s_Mean']]\n    speedMatrix = speedMatrix.rename(columns={str(monitorWindow) + 'beforeFeedSpeed_mm/s_Mean': \"Before\",\n                  \"duringFeedSpeed_mm/s_Mean\": \"During\", str(monitorWindow) + 'afterFeedSpeed_mm/s_Mean': 'After'})\n    \n    speedMatrixMelted = speedMatrix.melt(id_vars=['ChamberID', 'Genotype', 'Status', 'Temperature'],\n                value_vars=[\n     'Before', 'During', 'After'],\n     var_name='SpeedEpoch', value_name='Speed')\n    noOfGenotypes = len(speedMatrix.Genotype.unique())\n    noOfTemperature = len(speedMatrix.Temperature.unique())\n    dabestVersion = locoUtilities.checkDabestVersion()\n    if dabestVersion <= 0.39:\n        _speedCompareFig, _axes = plt.subplots(noOfTemperature, noOfGenotypes*2)\n        speedCompare = np.empty((noOfTemperature, noOfGenotypes*2), dtype=object)\n        for i in range(0, noOfTemperature):\n            for j in range(0, noOfGenotypes):\n                geno = speedMatrix.Genotype.unique()[j]\n                temp = speedMatrix.Temperature.unique()[i]\n                speedMatrix1 = speedMatrix.loc[(speedMatrix.Genotype == geno) & (speedMatrix.Temperature == temp)]\n                \n                speedCompare[i, 2*j] = dabest.load(speedMatrix1, idx=('Before', 'During'),\n                                                        paired=True, id_col='ChamberID')\n                speedCompare[i, 2*j].mean_diff.plot(ax = _axes[i, 2*j],\n                    swarm_label=('Average Speed (mm/s)'), float_contrast = False)\n                speedCompare[i, 2*j+1] = dabest.load(speedMatrix1, idx=('Before', 'After'),\n                                                        paired=True, id_col='ChamberID')\n                speedCompare[i, 2*j+1].mean_diff.plot(ax = _axes[i, 2*j+1],\n                    swarm_label=('Average Speed (mm/s)'), float_contrast = False)\n\n    else:\n        _speedCompareFig, _axes = plt.subplots(noOfTemperature, noOfGenotypes)\n        speedCompare = np.empty((noOfTemperature, noOfGenotypes), dtype=object)\n        for i in range(0, noOfTemperature):\n            for j in range(0, noOfGenotypes):\n                geno = speedMatrixMelted.Genotype.unique()[j]\n                temp = speedMatrixMelted.Temperature.unique()[i]\n                speedMatrix1 = speedMatrixMelted.loc[(speedMatrixMelted.Genotype == geno) & (speedMatrixMelted.Temperature == temp)]\n                speedCompare[i, j] = dabest.load(data=speedMatrix1,\n                                                id_col='ChamberID',\n                                                y='Speed',\n                                                x='SpeedEpoch',\n                                                idx=tuple(\n                                                    speedMatrix1['SpeedEpoch'].unique()),\n                                                paired='sequential')\n                speedCompare[i, j].mean_diff.plot(ax=_axes[i, j])\n    swarmRange = [_axes[i, j].get_ylim()\n                    for i in range(0, len(_axes)) for j in range(0, len(_axes[0]))]\n    contrastRange = [_axes[i, j].contrast_axes.get_ylim(\n              ) for i in range(0, len(_axes)) for j in range(0, len(_axes[0]))]\n    plt.close()\n    \n    speedCompareFig, axes = plt.subplots(len(_axes), len(_axes[0]))\n\n    for i in range(0, len(_axes)):\n        for j in range(0, len(_axes[0])):\n            speedCompare[i, j].mean_diff.plot(ax=axes[i, j], swarm_ylim=(np.min(swarmRange), np.max(swarmRange)),\n                                         contrast_ylim=(np.min(contrastRange), np.max(contrastRange)),color_col = 'Temperature', float_contrast = False)\n            if dabestVersion <=0.39:\n                if np.mod(j, 2)==0:\n                    axes[i, j].set_title(speedMatrix.Genotype.unique()[int(np.floor(j/2))-1])\n\n            else:    \n                axes[i, j].set_title(speedMatrix.Genotype.unique()[j])\n            if j != len(axes[0])-1:\n                axes[i, j].get_legend().remove()\n    if dabestVersion <= 0.39:\n        speedCompareFig.set_size_inches(8*(i+1), 2*(j+1))\n    else:\n        speedCompareFig.set_size_inches(7*(i+1), 4*(j+1))\n    locoUtilities.espressoSaveFig(speedCompareFig, locoObj.monitorMin +\n                                      'periFeedPairedSpeed', locoObj.metaDataDf.Date[0], locoObj.outputFolder)\n\n    return speedCompareFig, speedCompare\n        \n        #return speedMatrix, speedCompare, speedCompareFig\n #       speedMatrix, speedCompare, speedCompareFig = plotPerifeedSpeed(\n    #        locoObj)\n     #   return locoObj.meanPeriSpeed, speedMatrix, speedCompare, speedCompareFig\n\n\ndef createWesAndersonPalette():\n        \n    import seaborn as sns\n    import numpy as np\n\n    wes_colors = {}\n    wes_colors['lightgray'] = np.divide([110, 100, 102], 255)\n    wes_colors['orange'] = np.divide([230, 82,  15], 255)\n    wes_colors['cyan'] = np.divide([73, 186,  186], 255)\n    wes_colors['crimson'] = np.divide([173, 9,  16], 255)\n    wes_colors['ocre'] = np.divide([249, 166,  0], 255)\n    wes_colors['darkgray'] = np.divide([55, 57,  61], 255)\n    wes_colors['hotpink'] = np.divide([210, 78, 130], 255)\n    wes_colors['lakeblue'] = np.divide([82, 150, 228], 255)\n    wes_colors['eggplant'] = np.divide([120, 43, 102], 255)\n    wes_colors['verde'] = np.divide([74, 104, 41], 255)\n    wes_colors['chocolate'] = np.divide([65, 20, 17], 255)\n    wes_colors['midnight'] = np.divide([10, 42,  87], 255)\n    wes_colors['brick'] = np.divide([235, 59, 32], 255)\n    wes_colors['black'] = np.divide([12, 13, 24], 255)\n    wes_palette = tuple(map(tuple, wes_colors.values()))\n    # sns.palplot(wes_palette)\n    return wes_palette, wes_colors\n\n\ndef setAxesTicks(ax, axesState, gridState = False):\n    if axesState == False:\n        ax.set_xticks([])\n        ax.set_xticklabels([])\n        ax.set_yticks([])\n        ax.set_yticklabels([])\n    \n    if gridState == False:\n        ax.grid(None)"
  }
]